name: DropDax NameBio Scraper (FlareSolverr)

on:
  schedule:
    - cron: '*/30 * * * *' # Runs every 30 minutes
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    # --- SERVICE CONTAINER DEFINITION ---
    services:
      flaresolverr:
        image: flaresolverr/flaresolverr:latest
        ports:
          - 8191:8191
        # FIX: Use 'env' instead of 'environment'
        env:
          LOG_LEVEL: info
          TZ: America/New_York
          CAPTCHA_SOLVER: none 
    # ------------------------------------

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          pip install requests beautifulsoup4

      # Wait for FlareSolverr to start
      - name: Wait for FlareSolverr
        run: |
          echo "Waiting for FlareSolverr to start..."
          # Loop for up to 30 seconds checking if the service is up
          timeout 30s bash -c 'until curl -s http://localhost:8191/health > /dev/null; do sleep 2; done'
          echo "FlareSolverr is UP!"

      # Run the Python Scraper
      - name: Run Scraper
        env: 
          PROXY_URL: ${{ secrets.PROXY_URL }}
        run: python Bio_scraper.py

      # Commit Results
      - name: Commit and Push
        if: success()
        run: |
          git config --global user.name "DropDax Bot"
          git config --global user.email "bot@dropdax.com"
          # Stash any unstaged changes to avoid conflicts
          git stash || true
          git pull --rebase
          git stash pop || true
          git add namebio_data.csv
          git commit -m "Update NameBio Data [$(date)]" || echo "No changes to commit"
          git push
